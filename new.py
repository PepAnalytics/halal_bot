#!/root/halal_bot/venv/bin/python3
import os
import re
import logging
import mysql.connector
import requests
from pathlib import Path
from aiogram import Bot, Dispatcher, types
from aiogram.client.default import DefaultBotProperties
from aiogram.filters import Command
from aiogram.enums import ParseMode
from aiogram.types import Message, URLInputFile
from PIL import Image, ImageFilter, ImageOps
from pytesseract import TesseractError  # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ä–∞–∑–¥–µ–ª –∏–º–ø–æ—Ä—Ç–æ–≤
import pytesseract
from bs4 import BeautifulSoup
from fake_useragent import UserAgent
import html
import asyncio
from tenacity import retry, stop_after_attempt, wait_exponential
from difflib import SequenceMatcher
import time
import numpy as np
from dotenv import load_dotenv
import os
from pyzbar.pyzbar import decode


# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ .env
load_dotenv()
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
MYSQL_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'user': os.getenv('DB_USER', 'root'),
    'password': os.getenv('DB_PASSWORD', ''),
    'database': os.getenv('DB_NAME', 'halal_checker'),
    'auth_plugin': 'mysql_native_password'
}

TOKEN = os.getenv('BOT_TOKEN')
E_CODE_PATTERN = re.compile(r'\b[E¬£–ï]\d{3}[A-Z]?\b', re.IGNORECASE)  # –£—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
ADDITIVES_CACHE = []

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.DEBUG,  # –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ DEBUG –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –ª–æ–≥–æ–≤
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("bot_debug.log"),
        logging.StreamHandler()
    ]
)


# –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ò–ò
if not os.path.exists('models'):
    os.makedirs('models')


# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ö–∞–ª—è–ª—å/—Ö–∞—Ä–∞–º (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
HALAL_CLASSIFIER = None
try:
    HALAL_CLASSIFIER = pipeline(
        "text-classification",
        model="saved_model" if os.path.exists("saved_model") else "distilbert-base-uncased"
    )
except:
    logging.warning("–ò–ò-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑")




# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(token=TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher()
pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ User-Agent
ua = UserAgent()


# –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start
@dp.message(Command("start"))
async def cmd_start(message: Message):
    """–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞"""
    welcome_text = (
        "üïå <b>–ê—Å—Å–∞–ª—è–º—É –∞–ª–µ–π–∫—É–º, –¥–æ—Ä–æ–≥–∏–µ –±—Ä–∞—Ç—å—è –∏ —Å–µ—Å—Ç—Ä—ã!</b>\n\n"
        "–Ø - Halal Checker Bot, –≤–∞—à –ø–æ–º–æ—â–Ω–∏–∫ –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –¥–æ–∑–≤–æ–ª–µ–Ω–Ω–æ—Å—Ç–∏ –ø–∏—â–µ–≤—ã—Ö –¥–æ–±–∞–≤–æ–∫ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –ò—Å–ª–∞–º–∞.\n\n"
        "<b>–ö–∞–∫ —è —Ä–∞–±–æ—Ç–∞—é:</b>\n"
        "1. –í—ã –º–æ–∂–µ—Ç–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –º–Ω–µ <b>—Ñ–æ—Ç–æ —ç—Ç–∏–∫–µ—Ç–∫–∏</b> –ø—Ä–æ–¥—É–∫—Ç–∞ üì∏\n"
        "2. –ò–ª–∏ –≤–≤–µ—Å—Ç–∏ <b>E-–∫–æ–¥ –¥–æ–±–∞–≤–∫–∏</b> (–Ω–∞–ø—Ä–∏–º–µ—Ä, E202) üîç\n"
        "3. –ò–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å <b>–Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–±–∞–≤–∫–∏</b> (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–æ—Ä–±–∞—Ç –∫–∞–ª–∏—è)\n\n"
        "–Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ—Å—Ç–∞–≤ –∏ —Å–æ–æ–±—â—É:\n"
        "‚úÖ <b>–•–∞–ª—è–ª—å</b> - —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ –¥–æ–±–∞–≤–∫–∏\n"
        "‚ùå <b>–•–∞—Ä–∞–º</b> - –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ –¥–æ–±–∞–≤–∫–∏\n"
        "‚ö†Ô∏è <b>–°–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–µ</b> - —Ç—Ä–µ–±—É—é—â–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏\n"
        "‚ùì <b>–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ</b> - –∫–æ–≥–¥–∞ –Ω–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n\n"
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /help –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.\n\n"
        "<i>–ü—É—Å—Ç—å –ê–ª–ª–∞—Ö –ø—Ä–∏–º–µ—Ç –≤–∞—à–∏ –±–ª–∞–≥–∏–µ –¥–µ–ª–∞ –∏ —É–±–µ—Ä–µ–∂–µ—Ç –æ—Ç –∑–∞–ø—Ä–µ—Ç–Ω–æ–≥–æ!</i>"
    )
    await message.answer(welcome_text)


# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å–æ —à—Ç—Ä–∏—Ö-–∫–æ–¥–∞–º–∏
def extract_barcode(image_path: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —à—Ç—Ä–∏—Ö-–∫–æ–¥ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        with Image.open(image_path) as img:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —à—Ç—Ä–∏—Ö-–∫–æ–¥–∞
            img = img.convert('L')
            img = img.point(lambda p: 0 if p < 100 else 255)

            barcodes = decode(img)
            if barcodes:
                return barcodes[0].data.decode("utf-8")
        return ""
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —à—Ç—Ä–∏—Ö-–∫–æ–¥–∞: {e}")
        return ""

def get_product_info_from_google(barcode: str) -> dict:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥—É–∫—Ç–µ –ø–æ —à—Ç—Ä–∏—Ö-–∫–æ–¥—É —á–µ—Ä–µ–∑ Google —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7'
        }

        # –®–∞–≥ 1: –ü–æ–∏—Å–∫ –ø–æ —à—Ç—Ä–∏—Ö-–∫–æ–¥—É –≤ Google
        search_url = f"https://www.google.com/search?q={barcode}"
        response = requests.get(search_url, headers=headers, timeout=15)
        soup = BeautifulSoup(response.text, "html.parser")

        # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞
        product_name = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç"

        # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è
        name_selectors = [
            ('h1', {'class': 'DgZBFd'}),
            ('h1', {'class': 'qrShPb'}),
            ('h2', {'class': 'qrShPb'}),
            ('h1', {}),
            ('h2', {}),
            ('div', {'class': 'DgZBFd'}),
            ('div', {'class': 'SPZz6b'})
        ]

        for tag, attrs in name_selectors:
            element = soup.find(tag, attrs)
            if element:
                product_name = element.text.strip()
                if product_name and len(product_name) > 3:
                    break

        # –ï—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ, –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        if len(product_name) < 4:
            title = soup.find('title')
            if title:
                title_text = title.text
                # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —á–∞—Å—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞
                for remove in ['- Google Search', '‚Äì Google –ü–æ–∏—Å–∫']:
                    title_text = title_text.replace(remove, '')
                product_name = title_text.strip()

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–∞
        brand = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –±—Ä–µ–Ω–¥"
        brand_selectors = [
            ('div', {'class': 'w1C7Le'}),
            ('div', {'class': 'wDYxhc', 'data-attrid': 'subtitle'}),
            ('div', {'class': 'sL6Rbf'})
        ]

        for tag, attrs in brand_selectors:
            element = soup.find(tag, attrs)
            if element:
                brand = element.text.strip()
                if brand and len(brand) > 2:
                    break

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_url = ""
        img_selectors = [
            ('img', {'class': 'rg_i'}),
            ('img', {'class': 'XNo5Ab'}),
            ('img', {'class': 'sh-div__image'})
        ]

        for tag, attrs in img_selectors:
            element = soup.find(tag, attrs)
            if element and 'src' in element.attrs:
                image_url = element['src']
                if image_url.startswith('http'):
                    break

        # –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞
        result_link = ""
        result_element = soup.find('div', class_='tF2Cxc')
        if result_element:
            link = result_element.find('a')
            if link and 'href' in link.attrs:
                result_link = link['href']

        return {
            "name": product_name,
            "brand": brand,
            "image_url": image_url,
            "source_url": result_link or search_url
        }
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–¥—É–∫—Ç–µ: {e}")
        return {
            "name": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç",
            "brand": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞",
            "image_url": "",
            "source_url": f"https://www.google.com/search?q={barcode}"
        }


def search_product_composition(product_name: str, barcode: str) -> str:
    """–ò—â–µ—Ç —Å–æ—Å—Ç–∞–≤ –ø—Ä–æ–¥—É–∫—Ç–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7'
        }

        # –ï—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —à—Ç—Ä–∏—Ö-–∫–æ–¥ –≤ –∑–∞–ø—Ä–æ—Å–µ
        if "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π" in product_name.lower():
            search_query = f"{barcode} —Å–æ—Å—Ç–∞–≤ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã"
        else:
            search_query = f"{product_name} —Å–æ—Å—Ç–∞–≤ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã"

        # –ö–æ–¥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è URL
        encoded_query = requests.utils.quote(search_query)
        search_url = f"https://www.google.com/search?q={encoded_query}"

        response = requests.get(search_url, headers=headers, timeout=20)
        soup = BeautifulSoup(response.text, "html.parser")

        composition = ""

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ü–æ–∏—Å–∫ –≤ —Å–Ω–∏–ø–ø–µ—Ç–∞—Ö Google
        snippet_selectors = [
            ('div', {'class': 'BNeawe s3v9rd AP7Wnd'}),
            ('div', {'class': 'hgKElc'}),
            ('div', {'class': 'LGOjhe'}),
            ('div', {'class': 'kno-rdesc'})
        ]

        for tag, attrs in snippet_selectors:
            elements = soup.find_all(tag, attrs)
            for element in elements:
                text = element.get_text()
                if "—Å–æ—Å—Ç–∞–≤" in text.lower() or "–∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã" in text.lower():
                    composition = text
                    if len(composition) > 100:  # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —ç—Ç–æ –Ω–µ –∫–æ—Ä–æ—Ç–∫–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
                        return composition

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ü–æ–∏—Å–∫ –≤ –∫–∞—Ä—Ç–æ—á–∫–∞—Ö –∑–Ω–∞–Ω–∏–π
        knowledge_panel = soup.find('div', class_='kp-blk')
        if knowledge_panel:
            for panel in knowledge_panel.find_all('div', class_='wDYxhc'):
                if "—Å–æ—Å—Ç–∞–≤" in panel.text.lower():
                    composition = panel.get_text()
                    return composition

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        first_result = soup.find('div', class_='tF2Cxc')
        if first_result:
            link_element = first_result.find('a')
            if link_element and 'href' in link_element.attrs:
                result_url = link_element['href']

                try:
                    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    page_response = requests.get(result_url, headers=headers, timeout=25)
                    page_soup = BeautifulSoup(page_response.text, "html.parser")

                    # –ü–æ–∏—Å–∫ —Å–æ—Å—Ç–∞–≤–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                    keywords = ["—Å–æ—Å—Ç–∞–≤", "–∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã", "ingredients", "–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"]

                    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3.1: –ü–æ–∏—Å–∫ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
                    for keyword in keywords:
                        heading = page_soup.find(
                            lambda tag: tag.name in ['h2', 'h3', 'h4'] and keyword in tag.text.lower())
                        if heading:
                            next_element = heading.find_next_sibling()
                            if next_element:
                                composition = next_element.get_text()
                                if composition:
                                    return composition

                    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3.2: –ü–æ–∏—Å–∫ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö
                    for keyword in keywords:
                        table = page_soup.find('table', summary=lambda s: s and keyword in s.lower())
                        if not table:
                            table = page_soup.find('table', class_=lambda c: c and keyword in c.lower())

                        if table:
                            composition = table.get_text()
                            return composition

                    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3.3: –ü–æ–∏—Å–∫ –≤ div —Å –∫–ª–∞—Å—Å–∞–º–∏
                    composition_classes = ["composition", "ingredients", "product-ingredients", "product-composition"]
                    for cls in composition_classes:
                        div = page_soup.find('div', class_=cls)
                        if div:
                            composition = div.get_text()
                            return composition

                    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3.4: –ü–æ–∏—Å–∫ –ø–æ id
                    composition_ids = ["ingredients", "composition", "sostav"]
                    for id_name in composition_ids:
                        div = page_soup.find('div', id=id_name)
                        if div:
                            composition = div.get_text()
                            return composition

                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")

        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        return "–°–æ—Å—Ç–∞–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∏—Å–∫–∞—Ç—å –≤—Ä—É—á–Ω—É—é."

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–æ—Å—Ç–∞–≤–∞: {e}")
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ—Å—Ç–∞–≤ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏"


async def process_barcode(barcode: str, message: types.Message, image_path: Path):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —à—Ç—Ä–∏—Ö-–∫–æ–¥ –ø—Ä–æ–¥—É–∫—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    try:
        # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        await message.answer(f"üîç –ù–∞–π–¥–µ–Ω —à—Ç—Ä–∏—Ö-–∫–æ–¥: <b>{barcode}</b>\n–ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥—É–∫—Ç–µ...")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–¥—É–∫—Ç–µ
        product_info = get_product_info_from_google(barcode)

        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–¥—É–∫—Ç–µ
        product_text = (
            f"üì¶ <b>–ü—Ä–æ–¥—É–∫—Ç:</b> {product_info['name']}\n"
            f"üè≠ <b>–ë—Ä–µ–Ω–¥:</b> {product_info['brand']}\n"
            f"üîó <a href='{product_info['source_url']}'>–ò—Å—Ç–æ—á–Ω–∏–∫</a>"
        )

        # –ï—Å–ª–∏ –µ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ
        if product_info.get('image_url') and product_info['image_url'].startswith('http'):
            try:
                await message.answer_photo(
                    photo=product_info['image_url'],
                    caption=product_text
                )
            except Exception as e:
                logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {e}")
                await message.answer(product_text)
        else:
            await message.answer(product_text)

        # –ü–æ–∏—Å–∫ —Å–æ—Å—Ç–∞–≤–∞ –ø—Ä–æ–¥—É–∫—Ç–∞
        await message.answer("üß™ –ò—â—É —Å–æ—Å—Ç–∞–≤ –ø—Ä–æ–¥—É–∫—Ç–∞...")
        composition = search_product_composition(product_info['name'], barcode)

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if len(composition) > 1000:
            composition_display = composition[:500] + "...\n\n... [—Ç–µ–∫—Å—Ç —Å–æ–∫—Ä–∞—â–µ–Ω] ...\n\n" + composition[-500:]
        else:
            composition_display = composition

        await message.answer(f"üìù <b>–ù–∞–π–¥–µ–Ω–Ω—ã–π —Å–æ—Å—Ç–∞–≤:</b>\n{composition_display}")

        # –ê–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–∞–≤–∞
        await message.answer("üî¨ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ—Å—Ç–∞–≤ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ö–∞–ª—è–ª—å...")

        # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞—à –∫–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Å—Ç–∞–≤–∞
        # –í—Ä–µ–º–µ–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É
        analysis_result = "‚úÖ –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑: –ø—Ä–æ–¥—É–∫—Ç, –≤–µ—Ä–æ—è—Ç–Ω–æ, —Ö–∞–ª—è–ª—å"

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        result_text = (
            f"üïå <b>–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏:</b>\n{analysis_result}\n\n"
            f"‚ÑπÔ∏è <b>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:</b>\n"
            f"‚Ä¢ –≠—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, –¥–ª—è –≤–∞–∂–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–π—Ç–µ—Å—å —Å–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º–∏\n"
            f"‚Ä¢ –ï—Å–ª–∏ —Å–æ—Å—Ç–∞–≤ –Ω–µ–ø–æ–ª–Ω—ã–π, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞–π—Ç–∏ –±–æ–ª–µ–µ —Ç–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n"
            f"‚Ä¢ –û—Ç–ø—Ä–∞–≤—å—Ç–µ /help –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
        )

        await message.answer(result_text)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —à—Ç—Ä–∏—Ö-–∫–æ–¥–∞: {e}", exc_info=True)
        await message.answer(
            "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —à—Ç—Ä–∏—Ö-–∫–æ–¥–∞.\n\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–¥–∏–Ω –∏–∑ —ç—Ç–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤:\n"
            "1. –í–≤–µ–¥–∏—Ç–µ —à—Ç—Ä–∏—Ö-–∫–æ–¥ –≤—Ä—É—á–Ω—É—é (13-14 —Ü–∏—Ñ—Ä)\n"
            "2. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ —Å–æ—Å—Ç–∞–≤–∞ –ø—Ä–æ–¥—É–∫—Ç–∞\n"
            "3. –ü–æ–∏—â–∏—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ —Å–∞–π—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—è"
        )


def analyze_composition(composition: str) -> dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ—Å—Ç–∞–≤ –ø—Ä–æ–¥—É–∫—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ò–ò –∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    found_additives = []
    composition_lower = composition.lower()

    # –ü–æ–∏—Å–∫ E-–∫–æ–¥–æ–≤
    e_codes = re.findall(r'\b[E¬£–ï]\d{3}[A-Z]?\b', composition, re.IGNORECASE)
    normalized_codes = [re.sub(r'[¬£–ï]', 'E', code, flags=re.IGNORECASE) for code in e_codes]
    for code in e_codes:
        details = get_additive_details(code)
        if details:
            found_additives.append(details)

    # –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤
    for additive in ADDITIVES_CACHE:
        for term in additive['search_terms']:
            if term and term in composition_lower:
                found_additives.append(additive)
                break

    # 2. –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –¥–æ–±–∞–≤–∫–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    if found_additives:
        return {
            "method": "database",
            "additives": found_additives
        }

    # 3. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ò–ò-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    if HALAL_CLASSIFIER:
        try:
            result = HALAL_CLASSIFIER(composition[:500])
            label = result[0]['label']
            score = result[0]['score']

            status_map = {
                "LABEL_0": "halal",
                "LABEL_1": "haram",
                "LABEL_2": "suspicious"
            }

            return {
                "method": "ai",
                "status": status_map.get(label, "undefined"),
                "confidence": score,
                "explanation": f"–ò–ò –æ–ø—Ä–µ–¥–µ–ª–∏–ª —Å—Ç–∞—Ç—É—Å –∫–∞–∫ '{status_map.get(label, '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}' —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é {score:.2f}"
            }
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ò–ò-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")

    # 4. –ï—Å–ª–∏ –ò–ò –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    haram_keywords = ["—Å–≤–∏–Ω–∏–Ω–∞", "–±–µ–∫–æ–Ω", "–≤–µ—Ç—á–∏–Ω–∞", "—Å–∞–ª–æ", "gelatine", "–∂–µ–ª–∞—Ç–∏–Ω", "—Å—ã—á—É–∂–Ω—ã–π", "–ø–µ–ø—Å–∏–Ω", "e120",
                      "–∫–æ—à–µ–Ω–∏–ª—å", "—Å–ø–∏—Ä—Ç", "–∞–ª–∫–æ–≥–æ–ª—å"]
    halal_keywords = ["—Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω—ã–π", "–ø–∞–ª—å–º–æ–≤–æ–µ –º–∞—Å–ª–æ", "–ø–æ–¥—Å–æ–ª–Ω–µ—á–Ω–æ–µ –º–∞—Å–ª–æ"]

    haram_found = [kw for kw in haram_keywords if kw in composition_lower]
    halal_found = [kw for kw in halal_keywords if kw in composition_lower]

    if haram_found:
        status = "haram"
        explanation = f"–ù–∞–π–¥–µ–Ω—ã –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã: {', '.join(haram_found)}"
    elif halal_found:
        status = "halal"
        explanation = f"–ù–∞–π–¥–µ–Ω—ã —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã: {', '.join(halal_found)}"
    else:
        status = "suspicious"
        explanation = "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"

    return {
        "method": "keyword",
        "status": status,
        "explanation": explanation
    }


# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
@dp.message(Command("start", "help"))
async def cmd_start(message: Message):
    """–û–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –Ω–æ–≤—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏"""
    welcome_text = (
        "üïå <b>–ê—Å—Å–∞–ª—è–º—É –∞–ª–µ–π–∫—É–º, –¥–æ—Ä–æ–≥–∏–µ –±—Ä–∞—Ç—å—è –∏ —Å–µ—Å—Ç—Ä—ã!</b>\n\n"
        "–Ø - Halal Checker Bot, –≤–∞—à –ø–æ–º–æ—â–Ω–∏–∫ –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –¥–æ–∑–≤–æ–ª–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –ò—Å–ª–∞–º–∞.\n\n"
        "<b>–ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:</b>\n"
        "‚Ä¢ <b>–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —à—Ç—Ä–∏—Ö-–∫–æ–¥–æ–≤</b> - –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ —à—Ç—Ä–∏—Ö-–∫–æ–¥–∞ —Ç–æ–≤–∞—Ä–∞\n"
        "‚Ä¢ <b>–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–∞–≤–∞</b> - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–¥—É–∫—Ç–µ\n\n"
        "<b>–ö–∞–∫ —è —Ä–∞–±–æ—Ç–∞—é:</b>\n"
        "1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ <b>—Ñ–æ—Ç–æ —ç—Ç–∏–∫–µ—Ç–∫–∏</b> –ø—Ä–æ–¥—É–∫—Ç–∞ üì∏\n"
        "2. –ò–ª–∏ <b>—Ñ–æ—Ç–æ —à—Ç—Ä–∏—Ö-–∫–æ–¥–∞</b> —Ç–æ–≤–∞—Ä–∞\n"
        "3. –ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ <b>E-–∫–æ–¥ –¥–æ–±–∞–≤–∫–∏</b> (–Ω–∞–ø—Ä–∏–º–µ—Ä, E202) üîç\n"
        "4. –ò–ª–∏ –Ω–∞–ø–∏—à–∏—Ç–µ <b>–Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–±–∞–≤–∫–∏</b> (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–æ—Ä–±–∞—Ç –∫–∞–ª–∏—è)\n\n"
        "–Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ—Å—Ç–∞–≤ –∏ —Å–æ–æ–±—â—É:\n"
        "‚úÖ <b>–•–∞–ª—è–ª—å</b> - —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã\n"
        "‚ùå <b>–•–∞—Ä–∞–º</b> - –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã\n"
        "‚ö†Ô∏è <b>–°–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–µ</b> - —Ç—Ä–µ–±—É—é—â–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏\n\n"
        "<i>–ü—É—Å—Ç—å –ê–ª–ª–∞—Ö –ø—Ä–∏–º–µ—Ç –≤–∞—à–∏ –±–ª–∞–≥–∏–µ –¥–µ–ª–∞ –∏ —É–±–µ—Ä–µ–∂–µ—Ç –æ—Ç –∑–∞–ø—Ä–µ—Ç–Ω–æ–≥–æ!</i>"
    )
    await message.answer(welcome_text)


@dp.message(lambda message: message.photo)
async def handle_photo(message: types.Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ: —ç—Ç–∏–∫–µ—Ç–∫–∞ –∏–ª–∏ —à—Ç—Ä–∏—Ö-–∫–æ–¥"""
    temp_dir = Path("temp")
    temp_dir.mkdir(exist_ok=True)
    destination = None

    try:
        file_id = message.photo[-1].file_id
        file = await bot.get_file(file_id)
        destination = temp_dir / f"{file_id}.jpg"

        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        await bot.download(file=file, destination=destination)

        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª —è–≤–Ω–æ –ø–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        if destination.exists():
            with destination.open('rb'):
                pass  # –ü—Ä–æ—Å—Ç–æ —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ —Ñ–∞–π–ª –∑–∞–∫—Ä—ã—Ç

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        with Image.open(destination) as img:
            if img.width < 300 or img.height < 300:
                await message.answer(
                    "‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.")
                return

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —à—Ç—Ä–∏—Ö-–∫–æ–¥
        barcode = extract_barcode(destination)
        if barcode:
            await process_barcode(barcode, message, destination)
            return

        # –ï—Å–ª–∏ —à—Ç—Ä–∏—Ö-–∫–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ —ç—Ç–∏–∫–µ—Ç–∫—É
        await process_label(destination, message)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ: {e}")
        await message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ —Å –±–æ–ª–µ–µ —á–µ—Ç–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º.")
    finally:
        # –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫ –¥–æ—Å—Ç—É–ø–∞
        if destination and destination.exists():
            try:
                destination.unlink()
            except PermissionError as pe:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª: {pe}")
                # –ü–æ–ø—Ä–æ–±—É–µ–º —É–¥–∞–ª–∏—Ç—å –ø–æ–∑–∂–µ
                await asyncio.sleep(1)
                try:
                    destination.unlink()
                except Exception:
                    pass



async def process_barcode(barcode: str, message: types.Message, image_path: Path):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —à—Ç—Ä–∏—Ö-–∫–æ–¥ –ø—Ä–æ–¥—É–∫—Ç–∞"""
    try:
        # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        await message.answer(f"üîç –ù–∞–π–¥–µ–Ω —à—Ç—Ä–∏—Ö-–∫–æ–¥: <b>{barcode}</b>\n–ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥—É–∫—Ç–µ –≤ Google...")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–¥—É–∫—Ç–µ
        product_info = get_product_info_from_google(barcode)

        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–¥—É–∫—Ç–µ
        product_text = (
            f"üì¶ <b>–ü—Ä–æ–¥—É–∫—Ç:</b> {product_info['name']}\n"
            f"üè≠ <b>–ë—Ä–µ–Ω–¥:</b> {product_info['brand']}\n"
            f"üîó <a href='{product_info['source_url']}'>–ò—Å—Ç–æ—á–Ω–∏–∫ –≤ Google</a>"
        )

        # –ï—Å–ª–∏ –µ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ
        if product_info.get('image_url'):
            try:
                await message.answer_photo(
                    photo=product_info['image_url'],
                    caption=product_text
                )
            except:
                await message.answer(product_text)
        else:
            await message.answer(product_text)

        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
        time.sleep(1)

        # –ü–æ–∏—Å–∫ —Å–æ—Å—Ç–∞–≤–∞ –ø—Ä–æ–¥—É–∫—Ç–∞
        await message.answer("üß™ –ò—â—É —Å–æ—Å—Ç–∞–≤ –ø—Ä–æ–¥—É–∫—Ç–∞...")
        composition = search_product_composition(product_info['name'])

        if "–Ω–µ –Ω–∞–π–¥–µ–Ω" in composition.lower() or "–Ω–µ —É–¥–∞–ª–æ—Å—å" in composition.lower():
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–æ—Å—Ç–∞–≤ –ø—Ä–æ–¥—É–∫—Ç–∞. –í—ã –º–æ–∂–µ—Ç–µ –≤–≤–µ—Å—Ç–∏ –µ–≥–æ –≤—Ä—É—á–Ω—É—é.")
            return

        # –ê–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–∞–≤–∞
        await message.answer("üî¨ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ—Å—Ç–∞–≤ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ö–∞–ª—è–ª—å...")
        analysis = analyze_composition(composition)

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result_text = f"üìù <b>–°–æ—Å—Ç–∞–≤:</b>\n{composition[:500]}{'...' if len(composition) > 500 else ''}\n\n"

        if analysis["method"] == "database":
            status_names = {
                'halal': '‚úÖ –•–∞–ª—è–ª—å',
                'haram': '‚ùå –•–∞—Ä–∞–º',
                'suspicious': '‚ö†Ô∏è –°–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–µ',
                'undefined': '‚ùì –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ'
            }

            result_text += "üîç <b>–ù–∞–π–¥–µ–Ω—ã –¥–æ–±–∞–≤–∫–∏:</b>\n"
            for additive in analysis["additives"]:
                status = status_names.get(additive['status'], additive['status'])
                result_text += (
                    f"‚Ä¢ <b>{additive['code']}</b> - {additive['name']}\n"
                    f"  –°—Ç–∞—Ç—É—Å: {status}\n"
                    f"  –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {additive['category']}\n\n"
                )
        else:
            status_names = {
                'halal': '‚úÖ –•–∞–ª—è–ª—å',
                'haram': '‚ùå –•–∞—Ä–∞–º',
                'suspicious': '‚ö†Ô∏è –°–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–µ',
                'undefined': '‚ùì –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ'
            }
            status = status_names.get(analysis["status"], "‚ùì –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ")

            result_text += (
                f"üïå <b>–°—Ç–∞—Ç—É—Å:</b> {status}\n"
                f"üìã <b>–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:</b> {analysis.get('explanation', '')}\n"
                f"‚öôÔ∏è <b>–ú–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞:</b> {'–ò–ò-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä' if analysis['method'] == 'ai' else '–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞'}"
            )

        result_text += "\n\n‚ö†Ô∏è <i>–≠—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞. –î–ª—è –≤–∞–∂–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–π—Ç–µ—Å—å —Å–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º–∏ –ø–æ —Ö–∞–ª—è–ª—å.</i>"
        await message.answer(result_text)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —à—Ç—Ä–∏—Ö-–∫–æ–¥–∞: {e}")
        await message.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —à—Ç—Ä–∏—Ö-–∫–æ–¥–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")


# –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
def preprocess_image(image_path: Path) -> Image:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
    with Image.open(image_path) as img:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–µ—Ä—ã–π —Ü–≤–µ—Ç
        img = img.convert('L')

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        img = ImageOps.autocontrast(img, cutoff=2)

        # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–µ–∑–∫–æ—Å—Ç–∏
        img = img.filter(ImageFilter.SHARPEN)

        # –£–¥–∞–ª–µ–Ω–∏–µ —à—É–º–æ–≤
        img = img.filter(ImageFilter.MedianFilter(size=3))

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
        new_width = img.width * 2
        new_height = img.height * 2
        img = img.resize((new_width, new_height), Image.LANCZOS)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ numpy array –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        img_array = np.array(img)

        # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
        threshold = img_array.mean() * 0.8
        img = img.point(lambda p: 0 if p < threshold else 255)

        return img


async def extract_text_from_image(image_path: Path) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
    try:
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        processed_img = preprocess_image(image_path)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        debug_path = image_path.with_name(f"debug_{image_path.name}")
        processed_img.save(debug_path)

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Tesseract –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        custom_config = r'--oem 3 --psm 6 -l rus+eng+ukr'

        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
        text = ""
        for attempt in range(3):
            try:
                text = pytesseract.image_to_string(processed_img, config=custom_config)
                break
            except TesseractError as e:
                logging.warning(f"–û—à–∏–±–∫–∞ Tesseract (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
                await asyncio.sleep(0.5)

        # –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
        return clean_ocr_text(text)

    finally:
        # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        if debug_path.exists():
            debug_path.unlink()

def similar(a: str, b: str) -> float:
    """–í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –¥–≤—É–º—è —Å—Ç—Ä–æ–∫–∞–º–∏"""
    return SequenceMatcher(None, a, b).ratio()

# –ú–æ–∂–Ω–æ —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
THRESHOLD_SIMILARITY = 0.75  # 65%

def find_similar_additives(text: str, threshold: float = 0.7) -> list:
    """–ù–∞—Ö–æ–¥–∏—Ç –¥–æ–±–∞–≤–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É –Ω–∞–∑–≤–∞–Ω–∏—è –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—è"""
    found_codes = set()
    text_lower = text.lower()

    # 1. –ü–æ–∏—Å–∫ E-–∫–æ–¥–æ–≤ (—Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
    e_codes = re.findall(r'\b[E–ï¬£]\d{3,4}[a-zA-Z]?\b', text, re.IGNORECASE)
    for code in e_codes:
        normalized = re.sub(r'[¬£–ï]', 'E', code, flags=re.IGNORECASE).upper()
        found_codes.add(normalized)

    # 2. –ü–æ–∏—Å–∫ –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ –¥–æ–±–∞–≤–æ–∫
    for additive in ADDITIVES_CACHE:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–±–∞–≤–∫–∏
        if additive['name']:
            name_similarity = similar(additive['name'].lower(), text_lower)
            if name_similarity >= threshold:
                found_codes.add(additive['code'])
                continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–±–∞–≤–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if additive.get('description'):
            # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            desc_snippet = additive['description'][:50].lower()
            desc_similarity = similar(desc_snippet, text_lower)
            if desc_similarity >= threshold:
                found_codes.add(additive['code'])

    return list(found_codes)


# –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —ç—Ç–∏–∫–µ—Ç–∫–∏
async def process_label(image_path: Path, message: types.Message):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–æ—Ç–æ —ç—Ç–∏–∫–µ—Ç–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º E-–∫–æ–¥–æ–≤"""
    try:
        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        custom_config = r'--oem 3 --psm 6 -l rus+eng'
        text = pytesseract.image_to_string(str(image_path), config=custom_config)
        text = clean_ocr_text(text)

        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –≤—ã–≤–æ–¥ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        clean_text = text.replace('|', 'I').replace('[', 'I').replace(']', 'I')
        clean_text = re.sub(r'\s+', ' ', clean_text)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        await message.answer(f"üîç –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{html.escape(clean_text[:3000])}" +
                             ("..." if len(clean_text) > 3000 else ""))

        # –ò—â–µ–º E-–∫–æ–¥—ã –≤ —Ç–µ–∫—Å—Ç–µ
        found_codes = find_e_codes_in_text(text)

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–¥—ã, –∏—â–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ "—É—Å–∏–ª–∏—Ç–µ–ª–∏ –≤–∫—É—Å–∞"
        if not found_codes:
            taste_enhancers = re.search(r'—É—Å–∏–ª–∏—Ç–µ–ª–∏ –≤–∫—É—Å–∞[^\)]*\(([^\)]+)\)', text, re.IGNORECASE)
            if taste_enhancers:
                found_codes = find_e_codes_in_text(taste_enhancers.group(1))

        # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–±–∞–≤–æ–∫
        results = []
        unique_codes = set()
        for code in found_codes:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∫–æ–¥—ã
            if len(code) < 4 or code in unique_codes:
                continue

            unique_codes.add(code)
            details = await get_additive_details(code)
            if details:
                status_names = {
                    'halal': '‚úÖ –•–∞–ª—è–ª—å',
                    'haram': '‚ùå –•–∞—Ä–∞–º',
                    'suspicious': '‚ö†Ô∏è –°–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–µ',
                    'undefined': '‚ùì –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ'
                }
                status = status_names.get(details['status'], details['status'])
                results.append(
                    f"‚Ä¢ <b>{details['code']}</b> - {details['name']}\n"
                    f"  –°—Ç–∞—Ç—É—Å: {status}\n"
                    f"  –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {details['category']}\n"
                )

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        response_parts = []

        if results:
            response_parts.append("üîç <b>–ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–±–∞–≤–∫–∏ –≤ —Å–æ—Å—Ç–∞–≤–µ:</b>\n" + "\n".join(results))

            # –í–∞–∂–Ω–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–æ–ø—É—Å–∫–∞—Ö
            warning_msg = (
                "\n\n‚ö†Ô∏è <b>–í–Ω–∏–º–∞–Ω–∏–µ!</b> –≠—Ç–æ –Ω–µ –≤—Å–µ –¥–æ–±–∞–≤–∫–∏ –≤ –ø—Ä–æ–¥—É–∫—Ç–µ!\n"
                "–ï—Å–ª–∏ –≤—ã –≤–∏–¥–∏—Ç–µ –Ω–∞ —ç—Ç–∏–∫–µ—Ç–∫–µ –¥—Ä—É–≥–∏–µ E-–∫–æ–¥—ã –∏–ª–∏ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã, "
                "–ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Ö –≤—Ä—É—á–Ω—É—é:\n"
                "1. –í–≤–µ–¥–∏—Ç–µ E-–∫–æ–¥ –∫–æ–º–∞–Ω–¥–æ–π <code>/e –ö–û–î</code> (–Ω–∞–ø—Ä–∏–º–µ—Ä <code>/e E621</code>)\n"
                "2. –ò–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–±–∞–≤–∫–∏"
            )
            response_parts.append(warning_msg)
        else:
            response_parts.append("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å E-–∫–æ–¥—ã –≤ —Å–æ—Å—Ç–∞–≤–µ")
            response_parts.append(
                "\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ—Å—Ç–∞–≤ –≤—Ä—É—á–Ω—É—é –∏ –≤–≤–µ–¥–∏—Ç–µ "
                "E-–∫–æ–¥—ã –∫–æ–º–∞–Ω–¥–æ–π <code>/e –ö–û–î</code>"
            )

        # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        full_response = "\n".join(response_parts)
        await message.answer(full_response)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —ç—Ç–∏–∫–µ—Ç–∫–∏: {e}")
        await message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —ç—Ç–∏–∫–µ—Ç–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ —Å –±–æ–ª–µ–µ —á–µ—Ç–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º.")
    finally:
        # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if image_path.exists():
            try:
                image_path.unlink()
            except:
                pass


# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–∞–Ω–¥—É –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ E-–∫–æ–¥–∞
@dp.message(Command("e"))
async def check_e_code(message: Message):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π E-–∫–æ–¥"""
    args = message.text.split()
    if len(args) < 2:
        await message.answer("‚ÑπÔ∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ E-–∫–æ–¥ –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã /e\n–ü—Ä–∏–º–µ—Ä: <code>/e E621</code>")
        return

    e_code = args[1].upper().replace('–ï', 'E').replace('¬£', 'E')

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–¥–∞
    e_code = re.sub(r'[^E0-9]', '', e_code)
    if not re.match(r'^E\d{3,4}$', e_code):
        await message.answer("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç E-–∫–æ–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç: EXXX")
        return

    details = await get_additive_details(e_code)
    if not details:
        await message.answer(f"‚ùå –î–æ–±–∞–≤–∫–∞ {e_code} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
        return

    status_names = {
        'halal': '‚úÖ –•–∞–ª—è–ª—å',
        'haram': '‚ùå –•–∞—Ä–∞–º',
        'suspicious': '‚ö†Ô∏è –°–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–µ',
        'undefined': '‚ùì –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ'
    }
    status = status_names.get(details['status'], details['status'])

    response = (
        f"üîç <b>{details['code']} - {details['name']}</b>\n"
        f"üì¶ <b>–ö–∞—Ç–µ–≥–æ—Ä–∏—è:</b> {details['category'] or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'}\n"
        f"üïå <b>–°—Ç–∞—Ç—É—Å:</b> {status}\n\n"
    )

    if details.get('description'):
        response += f"üìù <b>–û–ø–∏—Å–∞–Ω–∏–µ:</b>\n{details['description'][:300]}\n\n"

    if details.get('condition_text'):
        response += f"‚ÑπÔ∏è <b>–£—Å–ª–æ–≤–∏–µ:</b> {details['condition_text']}"

    response += "\n\n‚ö†Ô∏è –≠—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞. –î–ª—è –≤–∞–∂–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–π—Ç–µ—Å—å —Å–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º–∏"

    await message.answer(response)
@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
async def download_file_with_retry(file, destination):
    return await bot.download(file, destination)


def clean_ocr_text(text: str) -> str:
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å–ª–µ OCR —Å —É—á–µ—Ç–æ–º —Ä—É—Å—Å–∫–æ–π '–µ'"""
    # –ó–∞–º–µ–Ω—è–µ–º —á–∞—Å—Ç–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–µ–º—ã–µ —Å–∏–º–≤–æ–ª—ã
    replacements = {
        'E ': 'E',
        '–ï ': 'E',
        '–µ ': 'E',  # —Ä—É—Å—Å–∫–∞—è –µ
        '¬£': 'E'
    }

    for wrong, correct in replacements.items():
        text = text.replace(wrong, correct)

    # –ó–∞–º–µ–Ω—è–µ–º —Ä—É—Å—Å–∫—É—é "–µ" –≤ –∫–æ–¥–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä "–µ322")
    text = re.sub(r'\b([–µ–ï])(\d{3})', r'E\2', text)
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤ E-–∫–æ–¥–∞—Ö
    text = re.sub(r'\b([E–ï])\s?(\d{3})\b', r'\1\2', text)

    return text


# –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ E-–∫–æ–¥–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
def find_e_codes_in_text(text: str) -> list:
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ E-–∫–æ–¥—ã –≤ —Ç–µ–∫—Å—Ç–µ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    # –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ–∏—Å–∫
    pattern = r'\b[E–ï¬£][\s\-]?\d{2,4}[a-zA-Z]?\b'
    matches = re.findall(pattern, text)

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤ —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö
    if not matches:
        matches = re.findall(r'\b[E–ï¬£][\s\-]?[–±–ë–∑–ó–û–æ–ê-–Ø–∞-—è\d]{3,4}\b', text)

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–¥–æ–≤
    normalized_codes = []
    for code in matches:
        clean_code = re.sub(r'[^E0-9]', '', code)
        clean_code = clean_code.replace('–û', '0').replace('–æ', '0')
        clean_code = clean_code.replace('–±', '6').replace('–ë', '6')
        clean_code = clean_code.replace('–∑', '3').replace('–ó', '3')

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∏–¥
        if re.match(r'^E\d{3,4}$', clean_code):
            normalized_codes.append(clean_code.upper())

    return list(set(normalized_codes))

@dp.message()
async def handle_text(message: Message):
    text = message.text.strip()

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è E-–∫–æ–¥–æ–≤
    if re.match(r'^[e–µE–ï]\d{3,4}[a-z]?$', text, re.IGNORECASE):
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –≤–µ—Ä—Ö–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ –∑–∞–º–µ–Ω—è–µ–º –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫—É—é –ï
        normalized_text = re.sub(r'[–µ–ï]', 'E', text).upper()
        details = await get_additive_details(normalized_text)
        if not details:
            return await message.answer(f"‚ùå –î–æ–±–∞–≤–∫–∞ {normalized_text} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –±–∞–∑–µ")
    else:
        # –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
        details = await get_additive_details(text)
        if not details:
            return await message.answer("‚ùå –î–æ–±–∞–≤–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞–ø–∏—Å–∞–Ω–∏—è.")

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    status_names = {
        'halal': '‚úÖ –•–∞–ª—è–ª—å',
        'haram': '‚ùå –•–∞—Ä–∞–º',
        'suspicious': '‚ö†Ô∏è –°–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–µ',
        'undefined': '‚ùì –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ'
    }
    status = status_names.get(details['status'], details['status'])

    response = (
        f"üîç <b>{details['code']} - {details['name']}</b>\n"
        f"üì¶ <b>–ö–∞—Ç–µ–≥–æ—Ä–∏—è:</b> {details['category'] or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'}\n"
        f"üïå <b>–°—Ç–∞—Ç—É—Å:</b> {status}\n\n"
    )

    if details.get('description'):
        clean_desc = details['description'].replace('"', '').strip()
        response += f"üìù <b>–û–ø–∏—Å–∞–Ω–∏–µ:</b>\n{clean_desc[:250]}{'...' if len(clean_desc) > 250 else ''}\n\n"

    if details.get('condition_text'):
        response += f"‚ÑπÔ∏è <b>–£—Å–ª–æ–≤–∏–µ:</b> {details['condition_text']}"

    await message.answer(response)


# –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–±–∞–≤–æ–∫
async def cache_additives():
    global ADDITIVES_CACHE, TERM_INDEX
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –≤—Å–µ—Ö —Ä—É—Å—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –æ–ø–∏—Å–∞–Ω–∏—è"""
    conn = None
    try:
        conn = mysql.connector.connect(**MYSQL_CONFIG)
        with conn.cursor(dictionary=True) as cursor:
            cursor.execute("SELECT code, name, category, description, status, condition_text FROM additives")

            ADDITIVES_CACHE.clear()
            for row in cursor:
                search_terms = set()

                # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–¥ –≤ —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞—Ö
                search_terms.add(row['code'].lower())  # e100
                search_terms.add(row['code'].upper())  # E100
                search_terms.add(row['code'])  # E100


                # –†—É—Å—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                russian_name = row['name'].strip().lower()
                search_terms.add(russian_name)

                # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ –∑–Ω–∞—á–∏–º—ã–µ —á–∞—Å—Ç–∏
                name_parts = re.split(r'[,/]', russian_name)
                for part in name_parts:
                    clean_part = part.strip()
                    if len(clean_part) > 3:
                        search_terms.add(clean_part)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
                if row.get('description'):
                    desc = row['description'].lower()

                    # 1. –ò—â–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –≤ —Å–∫–æ–±–∫–∞—Ö
                    synonyms = re.findall(r'\((.*?)\)', desc)
                    for synonym in synonyms:
                        # –†–∞–∑–¥–µ–ª—è–µ–º —Å–ø–∏—Å–∫–∏ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
                        for syn in re.split(r'[,;]', synonym):
                            clean_syn = syn.strip()
                            if len(clean_syn) > 3:
                                search_terms.add(clean_syn)

                    # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã (—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ)
                    nouns = re.findall(r'\b[–∞-—è—ë]{4,}\b', desc)
                    search_terms.update(nouns[:8])

                    # 3. –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –µ—Å–ª–∏ –µ—Å—Ç—å
                    english_terms = re.findall(r'\b[a-z]{4,}\b', desc)
                    search_terms.update(english_terms[:3])

                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                filtered_terms = {term for term in search_terms if len(term) > 2}

                # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–±–∞–≤–∫–µ
                additive_data = {
                    'code': row['code'].upper(),
                    'name': row['name'],
                    'category': row['category'],
                    'status': row['status'],
                    'description': row['description'],
                    'condition_text': row['condition_text'],
                    'search_terms': filtered_terms
                }
                ADDITIVES_CACHE.append(additive_data)


        logging.info(f"–ö—ç—à–∏—Ä–æ–≤–∞–Ω–æ {len(ADDITIVES_CACHE)} –¥–æ–±–∞–≤–æ–∫")

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è: {e}", exc_info=True)
    finally:
        if conn and conn.is_connected():
            conn.close()
    TERM_INDEX = {}
    for additive in ADDITIVES_CACHE:
        for term in additive['search_terms']:
            if term not in TERM_INDEX:
                TERM_INDEX[term] = []
            TERM_INDEX[term].append(additive['code'])

    logging.info(f"–°–æ–∑–¥–∞–Ω –∏–Ω–¥–µ–∫—Å –¥–ª—è {len(TERM_INDEX)} —Ç–µ—Ä–º–∏–Ω–æ–≤")

def find_in_cache(term: str) -> dict | None:
    term = term.lower().strip()

    # 0. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–æ–¥–∞
    for additive in ADDITIVES_CACHE:
        if term == additive['code'].lower():
            return additive

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –≤—Å–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–º —Ç–µ—Ä–º–∏–Ω–∞–º
        if term in additive['search_terms']:
            return additive

    # 2. –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ —Ç–µ—Ä–º–∏–Ω–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–∂–µ–ª–∞—Ç" –¥–ª—è "–∂–µ–ª–∞—Ç–∏–Ω")
    for additive in ADDITIVES_CACHE:
        for stored_term in additive['search_terms']:
            if term in stored_term or stored_term in term:
                return additive

    # 3. –ü–æ–∏—Å–∫ –ø–æ –∫–æ—Ä–Ω—é —Å–ª–æ–≤–∞ (–ø—Ä–∏–º–∏—Ç–∏–≤–Ω–∞—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è)
    root = term
    if len(term) > 4:
        # –î–ª—è —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤ —É–¥–∞–ª—è–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏—è
        if term.endswith(('–∏–Ω', '–∞–Ω', '—ã–Ω', '–æ–≤')):
            root = term[:-2]
        elif term.endswith(('—ã–π', '–∏–π', '–æ–π', '–∞—è', '—è—è', '–æ–µ', '–µ–µ')):
            root = term[:-2]

    for additive in ADDITIVES_CACHE:
        for stored_term in additive['search_terms']:
            if stored_term.startswith(root):
                return additive

    # 4. Fuzzy-–ø–æ–∏—Å–∫ –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å—Ç—Ä–æ–∫
    best_match = None
    best_score = 0.0

    for additive in ADDITIVES_CACHE:
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∫–æ–¥–æ–º
        code_score = similar(term, additive['code'].lower())
        if code_score > best_score:
            best_score = code_score
            best_match = additive

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–æ –≤—Å–µ–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏
        for stored_term in additive['search_terms']:
            term_score = similar(term, stored_term)
            if term_score > best_score:
                best_score = term_score
                best_match = additive

    # –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ 70%
    if best_score > 0.7:
        return best_match

    return None


def find_additives_in_text(text: str, threshold: float = 0.75) -> list:
    """–ü–æ–∏—Å–∫ –¥–æ–±–∞–≤–æ–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º NLP-–ø–æ–¥—Ö–æ–¥–æ–≤"""
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
    text = text.lower().translate(str.maketrans('', '', string.punctuation))

    found_additives = []

    # 1. –ü–æ–∏—Å–∫ —Ç–æ—á–Ω—ã—Ö E-–∫–æ–¥–æ–≤
    e_codes = re.findall(r'\b[–µe]\d{3,4}[a-z]?\b', text)
    for code in set(e_codes):
        normalized = code.upper().replace('–ï', 'E')
        found_additives.append(normalized)

    # 2. –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ç–µ—Ä–º–∏–Ω–∞–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—ç—à–∞
    keywords = ["–∫—Ä–∞—Å–∏—Ç–µ–ª—å", "–∫–æ–Ω—Å–µ—Ä–≤–∞–Ω—Ç", "—ç–º—É–ª—å–≥–∞—Ç–æ—Ä", "—Å—Ç–∞–±–∏–ª–∏–∑–∞—Ç–æ—Ä", "–∞–Ω—Ç–∏–æ–∫—Å–∏–¥–∞–Ω—Ç"]
    for keyword in keywords:
        if keyword in text:
            for additive in ADDITIVES_CACHE:
                if additive['category'] and keyword in additive['category'].lower():
                    found_additives.append(additive['code'])

    # 3. –ü–æ–∏—Å–∫ –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
    if len(found_additives) == 0:
        text_tokens = set(text.split())
        for additive in ADDITIVES_CACHE:
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ –ø–æ Jaccard
            additive_tokens = set(additive['name'].lower().split())
            similarity = len(text_tokens & additive_tokens) / len(text_tokens | additive_tokens)

            if similarity > threshold:
                found_additives.append(additive['code'])

    return list(set(found_additives))

# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ –ë–î
async def get_additive_details(search_term: str) -> dict:
    logging.info(f"–ü–æ–∏—Å–∫ –¥–æ–±–∞–≤–∫–∏: {search_term}")
    conn = None
    cursor = None
    try:
        conn = mysql.connector.connect(**MYSQL_CONFIG)
        cursor = conn.cursor(dictionary=True, buffered=True)

        # –ü–æ–∏—Å–∫ –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –∫–æ–¥–∞
        cursor.execute("SELECT * FROM additives WHERE code = %s", (search_term,))
        result = cursor.fetchone()
        if result:
            logging.info(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ –∫–æ–¥—É: {search_term}")
            return result

        # –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é (—Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
        cursor.execute("SELECT * FROM additives WHERE LOWER(name) = %s", (search_term.lower(),))
        result = cursor.fetchone()
        if result:
            logging.info(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ —Ç–æ—á–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é: {search_term}")
            return result

        # –ü–æ–∏—Å–∫ –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
        cursor.execute("SELECT * FROM additives WHERE LOWER(name) LIKE %s", (f"%{search_term.lower()}%",))
        result = cursor.fetchone()
        if result:
            logging.info(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é: {search_term}")
            return result

        logging.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ: {search_term}")
        return None

    except mysql.connector.Error as err:
        logging.error(f"–û—à–∏–±–∫–∞ MySQL: {err}")
        return None
    finally:
        if cursor:
            cursor.close()
        if conn and conn.is_connected():
            conn.close()

@dp.message(Command("help"))
async def cmd_help(message: Message):
    help_text = (
        "üìã <b>Halal Checker Bot - –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è</b>\n\n"
        "üñºÔ∏è <b>1. –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ —ç—Ç–∏–∫–µ—Ç–∫–∏</b>\n"
        "–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ —Å–æ—Å—Ç–∞–≤–∞ –ø—Ä–æ–¥—É–∫—Ç–∞. –Ø –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—é —Ç–µ–∫—Å—Ç –∏ –ø—Ä–æ–≤–µ—Ä—é –≤—Å–µ –ø–∏—â–µ–≤—ã–µ –¥–æ–±–∞–≤–∫–∏!\n\n"
        "üî¢ <b>2. –ü–æ–∏—Å–∫ –ø–æ E-–∫–æ–¥—É</b>\n"
        "–í–≤–µ–¥–∏—Ç–µ –∫–æ–¥ –¥–æ–±–∞–≤–∫–∏: <code>E202</code> –∏–ª–∏ <code>–ï415</code> (–º–æ–∂–Ω–æ –∫–∞–∫ –ª–∞—Ç–∏–Ω–∏—Ü–µ–π, —Ç–∞–∫ –∏ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π)\n\n"
        "üìù <b>3. –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é</b>\n"
        "–ù–∞–ø–∏—à–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–±–∞–≤–∫–∏: <code>—Å–æ—Ä–±–∞—Ç –∫–∞–ª–∏—è</code> –∏–ª–∏ <code>–≥–ª—É—Ç–∞–º–∞—Ç –Ω–∞—Ç—Ä–∏—è</code>\n\n"
        "üîÑ <b>4. –ü–æ–∏—Å–∫ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é</b>\n"
        "–ú–æ–∂–Ω–æ –∏—Å–∫–∞—Ç—å –ø–æ —Å–ª–æ–≤–∞–º –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è: <code>–∫—Ä–∞—Å–∏—Ç–µ–ª—å</code> –∏–ª–∏ <code>—ç–º—É–ª—å–≥–∞—Ç–æ—Ä</code>\n\n"
        "üìä <b>–°–∏—Å—Ç–µ–º–∞ —Å—Ç–∞—Ç—É—Å–æ–≤:</b>\n"
        "‚úÖ <b>–•–∞–ª—è–ª—å</b> - —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ –¥–æ–±–∞–≤–∫–∏\n"
        "‚ùå <b>–•–∞—Ä–∞–º</b> - –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ –¥–æ–±–∞–≤–∫–∏\n"
        "‚ö†Ô∏è <b>–°–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–µ</b> - —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏\n"
        "‚ùì <b>–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ</b> - –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n\n"
        "üí° <b>–í–∞–∂–Ω–æ!</b> –ë–æ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç –∫–∞–∫ –ª–∞—Ç–∏–Ω—Å–∫–∏–µ <code>E</code>, —Ç–∞–∫ –∏ –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ <code>–ï</code> –≤ –∫–æ–¥–∞—Ö –¥–æ–±–∞–≤–æ–∫\n\n"
        "üì¨ <b>–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å:</b>\n"
        "–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –ø–æ–∂–µ–ª–∞–Ω–∏—è, –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ @–≤–∞—à_–∞–¥–º–∏–Ω"
    )
    await message.answer(help_text)


@dp.message(lambda message: message.photo)
@dp.message(lambda message: message.photo)
async def handle_photo(message: types.Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ–æ—Ç–æ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π"""
    temp_dir = Path("temp_images")
    temp_dir.mkdir(exist_ok=True)

    try:
        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ
        file_id = message.photo[-1].file_id
        file = await bot.get_file(file_id)
        dest_path = temp_dir / f"{file_id}.jpg"

        await bot.download(file, dest_path)

        # –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —à—Ç—Ä–∏—Ö-–∫–æ–¥
        barcode = extract_barcode(dest_path)

        if barcode:
            await message.answer(f"üì¶ –ù–∞–π–¥–µ–Ω —à—Ç—Ä–∏—Ö-–∫–æ–¥: {barcode}")
            await process_barcode(barcode, message, dest_path)
        else:
            await message.answer("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ—Å—Ç–∞–≤ –ø—Ä–æ–¥—É–∫—Ç–∞...")
            await process_label(dest_path, message)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ: {str(e)}")
        await message.answer("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ —Ñ–æ—Ç–æ.")

    finally:
        # –û—Ç–ª–æ–∂–µ–Ω–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
        await asyncio.sleep(10)
        if dest_path.exists():
            try:
                dest_path.unlink()
            except:
                pass


@dp.message()
async def handle_text(message: Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    text = message.text.strip()

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–≤–æ–¥–∞
    normalized_text = text.strip()

    if not text:
        return await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ–¥ –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∏—â–µ–≤–æ–π –¥–æ–±–∞–≤–∫–∏")

    # –ü–æ–∏—Å–∫ –≤ –∫—ç—à–µ —Å —É—á–µ—Ç–æ–º —á–∞—Å—Ç–∏—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    found_in_cache = []
    for additive in ADDITIVES_CACHE:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–¥
        if normalized_text == additive['code'].lower():
            found_in_cache.append(additive)
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —Å–∏–Ω–æ–Ω–∏–º—ã
        for term in additive['search_terms']:
            if normalized_text in term or term in normalized_text:
                found_in_cache.append(additive)
                break

    if found_in_cache:
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é –¥–æ–±–∞–≤–∫—É
        details = found_in_cache[0]
    else:
        # –ü–æ–∏—Å–∫ –≤ –ë–î —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LIKE –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        details = await get_additive_details(normalized_text)

    if not details:
        # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        suggestions = []
        for additive in ADDITIVES_CACHE:
            if SequenceMatcher(None, normalized_text, additive['name'].lower()).ratio() > 0.6:
                suggestions.append(additive['name'])

        if suggestions:
            unique_suggestions = list(set(suggestions))[:5]
            reply = "‚ùå –¢–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è. –í–æ–∑–º–æ–∂–Ω–æ –≤—ã –∏—Å–∫–∞–ª–∏:\n" + "\n".join(f"‚Ä¢ {s}" for s in unique_suggestions)
            return await message.answer(reply)

        return await message.answer("‚ùå –î–æ–±–∞–≤–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ –∏–ª–∏ —É—Ç–æ—á–Ω–∏—Ç–µ –∑–∞–ø—Ä–æ—Å.")

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
    status_names = {
        'halal': '‚úÖ –•–∞–ª—è–ª—å',
        'haram': '‚ùå –•–∞—Ä–∞–º',
        'suspicious': '‚ö†Ô∏è –°–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–µ',
        'undefined': '‚ùì –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ'
    }
    status = status_names.get(details['status'], details['status'])

    response = (
        f"üîç <b>{details['code']} - {details['name']}</b>\n"
        f"üì¶ <b>–ö–∞—Ç–µ–≥–æ—Ä–∏—è:</b> {details['category'] or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'}\n"
        f"üïå <b>–°—Ç–∞—Ç—É—Å:</b> {status}\n\n"
    )

    if details.get('description'):
        clean_desc = details['description'].replace('"', '').strip()
        response += f"üìù <b>–û–ø–∏—Å–∞–Ω–∏–µ:</b>\n{clean_desc[:250]}{'...' if len(clean_desc) > 250 else ''}\n\n"

    if details.get('condition_text'):
        response += f"‚ÑπÔ∏è <b>–£—Å–ª–æ–≤–∏–µ:</b> {details['condition_text']}"

    await message.answer(response)

async def main():
    await cache_additives()
    await dp.start_polling(bot)


if __name__ == '__main__':
    import asyncio
    asyncio.run(main())
